{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63623daf7993ffb",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Introduction to `PyTorch` -- Building ML models\n",
    "\n",
    "[Deep Learning](https://dsai.units.it/index.php/courses/deep-learning/) Course @ [UniTS](https://portale.units.it/en), Spring 2024\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/emaballarin/deeplearning-units/blob/main/labs/01_intro_to_pytorch/02_pytorch_models.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preliminary infrastucture setup",
   "id": "9efd284c13fc6ea5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:58.686844Z",
     "start_time": "2024-02-27T17:27:57.286870Z"
    }
   },
   "cell_type": "code",
   "source": "!python -m pip install -q pip_install_if_missing",
   "id": "a89c9b057229a895",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:58.746446Z",
     "start_time": "2024-02-27T17:27:58.689659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from piim import pip_install_if_missing\n",
    "\n",
    "pip_install_if_missing(\"icecream\")"
   ],
   "id": "1e489ddb0875803",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:58.777738Z",
     "start_time": "2024-02-27T17:27:58.748187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pretty printouts\n",
    "from icecream import ic\n",
    "\n",
    "ic.configureOutput(outputFunction=print)\n",
    "ic.configureOutput(prefix=\"    | \")"
   ],
   "id": "b4519a0e7269d06a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Some imports",
   "id": "5951ffbf0d96ab1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.632898Z",
     "start_time": "2024-02-27T17:27:58.780228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as th\n",
    "from safetensors.torch import save_file as safe_save_file\n",
    "from safetensors.torch import save_model as safe_save_model\n",
    "from safetensors.torch import load_model as safe_load_model\n",
    "from torch import Tensor"
   ],
   "id": "c13a187452f5e5d0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example: Linear regression...",
   "id": "ebe8efc22cda0fc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ... with *bare tensors*\n",
    "By using all the pieces we've seen till now, we can build our first *model* using PyTorch: a linear regressor, *i.e.*:\n",
    "\n",
    "$$\n",
    "y = XW + b\n",
    "$$\n",
    "\n",
    "which can also be simplified as:\n",
    "\n",
    "$$\n",
    "y = XW\n",
    "$$\n",
    "\n",
    "if we incorporate the bias $b$ inside $W$ and add to the $X$ a column of ones to the right."
   ],
   "id": "c45e288aaed21573"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We start by generating our data. We randomly sample $X$ as a $N\\times P$ tensor, meaning that we have 1000 datapoints and 100 features and produce $y$ as:\n",
    "$$\n",
    "y=XM+\\mathcal{N}(0,I)\n",
    "$$\n",
    "where $M$ is a randomly drawn projection vector (shape $P\\times 1$, same as our weights).\n",
    "We are adding some iid gaussian noise on the $y$ to avoid the interpolation regime, in which we could be fitting our data perfectly using a linear model."
   ],
   "id": "862efcec61c47a09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.640675Z",
     "start_time": "2024-02-27T17:27:59.634754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N: int = 1000\n",
    "P: int = 100\n",
    "X_orig: Tensor = th.rand(N, P)\n",
    "M: Tensor = th.rand(P, 1)\n",
    "y: Tensor = X_orig @ M + th.normal(\n",
    "    mean=th.zeros(N, 1), std=th.ones(N, 1)\n",
    ")  # Convenience functions: `th.zeros`, `th.ones`\n",
    "# Also: PyTorch supports probability distributions (e.g. `th.normal`)"
   ],
   "id": "a06636304ac3490",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can add a column of ones to $X$ to include the bias:",
   "id": "9ea9b586a411ab58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.646375Z",
     "start_time": "2024-02-27T17:27:59.642278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X: Tensor = th.cat(\n",
    "    tensors=[X_orig, th.ones(N, 1)], dim=1\n",
    ")  # `th.cat` concatenates tensors along a given dimension"
   ],
   "id": "ea39e1e84547f0de",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The regressor can be fit with classical statistical methods such as Ordinary Least Squares (OLS), and the optimal $W$ has the form:\n",
    "\n",
    "$$\n",
    "W^*=(X^TX)^{-1}X^Ty\n",
    "$$"
   ],
   "id": "dc5a495beb1b2c13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.659154Z",
     "start_time": "2024-02-27T17:27:59.647807Z"
    }
   },
   "cell_type": "code",
   "source": "W_star: Tensor = ((X.T @ X).inverse()) @ X.T @ y",
   "id": "7456423463d739ca",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To assess the quality of this fit we can evaluate the Mean Squared Error (MSE) between the original $y$ and the prediction:",
   "id": "e3609277e1816a59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.676630Z",
     "start_time": "2024-02-27T17:27:59.661120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss: Tensor = th.nn.functional.mse_loss(input=X @ W_star, target=y)\n",
    "_ = ic(loss)"
   ],
   "id": "dcff08ee1210bb8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | loss: tensor(0.8463)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fitted model parameters can be saved (and loaded afterwards) using the `torch.save` (and `torch.load`) function:",
   "id": "7507863737b2327c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.682565Z",
     "start_time": "2024-02-27T17:27:59.678439Z"
    }
   },
   "cell_type": "code",
   "source": "th.save(W_star, \"./W_star_ols.pt\")",
   "id": "c3a369a5e051f82e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Note**:\n",
    "\n",
    "The `torch.save` function is not limited to save tensors, but can be used to save any kind of object (e.g. models, optimizers, etc.). Under the hood, it uses the (in)famous `pickle` module.\n",
    "\n",
    "Such setup allows for great convenience, but also for potential security risks. Be careful when loading objects from untrusted sources. Or use [`safetensors`](https://github.com/huggingface/safetensors) instead!"
   ],
   "id": "6c9379f4b1436131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.690012Z",
     "start_time": "2024-02-27T17:27:59.685737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "safe_save_file(\n",
    "    {\"W_star\": W_star}, \"./W_star_ols_safe.pt\"\n",
    ")  # The only difference: the saved tensor should be named."
   ],
   "id": "e8e834c0bed4bcd0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ... with a `torch.nn.Module`",
   "id": "a6edc89d502716"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The same linear regression model can be implemented using the `torch.nn.Module` class. This is the recommended way to build models in PyTorch, as it allows for a more structured and modular approach, and for gradient-based optimization of model parameters.\n",
    "\n",
    "In general, a PyTorch model is a Python class that inherits from `torch.nn.Module` and implements (at least) these two methods:\n",
    "\n",
    "1. `__init__`: the constructor, in which we **must** define all learnable parameters of the model (directly as `torch.nn.Parameters`s, or as members of other class objects);\n",
    "2. `forward`: the method that specifies how input data fed into the model need to be processed in order to produce some outputs.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "In our case, the transformation of the inputs we are looking for is already implemented by the `torch.nn.Linear` class, which is a subclass of `torch.nn.Module` itself. We can use it to build our linear regressor."
   ],
   "id": "e04ab72fb865c317"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.697097Z",
     "start_time": "2024-02-27T17:27:59.691503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LinearRegressor(th.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.affine_transform = th.nn.Linear(\n",
    "            in_features=in_features, out_features=out_features, bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.affine_transform(x)\n",
    "\n",
    "    # Just for the fun of it, we can add a method to fit the model using OLS.\n",
    "    # With gradient-based optimization, this would not be necessary. But it's a good exercise.\n",
    "    def ols_fit(self, xols: Tensor, yols: Tensor) -> None:\n",
    "        with th.no_grad():\n",
    "            xols = th.cat(tensors=[xols, th.ones(xols.shape[0], 1)], dim=1)\n",
    "            wols: Tensor = ((xols.T @ xols).inverse()) @ xols.T @ yols\n",
    "            self.affine_transform.weight.data = (\n",
    "                wols[: self.affine_transform.in_features].T.detach().clone()\n",
    "            )\n",
    "            self.affine_transform.bias.data = wols[-1].detach().clone()"
   ],
   "id": "2e40ab063994afe5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we can fit the model on the same data as before:",
   "id": "55b5ebab871b1fbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.703176Z",
     "start_time": "2024-02-27T17:27:59.698197Z"
    }
   },
   "cell_type": "code",
   "source": "model: LinearRegressor = LinearRegressor(in_features=P, out_features=1, bias=True)",
   "id": "804005a7146a902e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.708793Z",
     "start_time": "2024-02-27T17:27:59.704783Z"
    }
   },
   "cell_type": "code",
   "source": "model.ols_fit(X_orig, y)",
   "id": "3e9d545ebabdbf77",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And we can evaluate the loss as before:",
   "id": "418a8c856a84bf43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.713237Z",
     "start_time": "2024-02-27T17:27:59.710054Z"
    }
   },
   "cell_type": "code",
   "source": "loss: Tensor = th.nn.functional.mse_loss(input=model(X_orig), target=y)",
   "id": "f91ddc5352e0c666",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can inspect the current parameters of our model by either direct access, or by using the `state_dict` method.",
   "id": "e0f1e54cec97ff2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.732380Z",
     "start_time": "2024-02-27T17:27:59.714508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_ = ic(model.affine_transform.weight)\n",
    "_ = ic(model.affine_transform.bias)"
   ],
   "id": "84abbb20495d59ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | model.affine_transform.weight: Parameter containing:\n",
      "                                     tensor([[ 0.4736,  0.6117,  0.4243,  0.2620,  0.9182,  0.3229,  0.8174,  0.6112,\n",
      "                                               0.3560,  0.2729,  0.9601, -0.0692,  0.5104,  0.6007,  0.5374,  0.6274,\n",
      "                                               0.9124,  0.9962,  1.1056,  0.3875, -0.0514,  0.7237,  0.1895,  0.6909,\n",
      "                                               0.7125,  0.6118,  0.9465,  0.6319,  0.0056,  0.1831,  0.4516,  0.3065,\n",
      "                                               0.4343,  0.4820,  0.1544,  0.6309,  0.2235,  0.1073,  0.8527,  0.2892,\n",
      "                                               0.4805,  0.7422,  0.6793,  0.2633, -0.0582,  0.3572,  0.2951,  0.2120,\n",
      "                                               0.3565,  0.4107,  0.1752,  0.7101,  0.1927,  0.5644,  0.6210,  0.8785,\n",
      "                                               0.3233,  0.2825,  1.0261,  0.0482,  0.9993,  0.5751,  0.7620,  0.6761,\n",
      "                                               0.5273,  0.2756,  0.8534,  0.5724,  0.6046,  0.1952,  0.1055,  0.5254,\n",
      "                                               0.3604,  0.6538,  0.2553,  0.9075,  0.3553,  0.2644,  0.2263,  0.0886,\n",
      "                                               0.8300,  0.5059,  0.1300,  0.1891,  0.1983,  0.7998,  0.3091,  0.0628,\n",
      "                                               0.9685,  0.7090,  0.8935,  0.1009,  0.3639,  0.9323,  0.1945,  0.7752,\n",
      "                                               0.2853,  0.8915,  0.6644,  0.0676]], requires_grad=True)\n",
      "    | model.affine_transform.bias: Parameter containing:\n",
      "                                   tensor([-0.2151], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.747173Z",
     "start_time": "2024-02-27T17:27:59.733980Z"
    }
   },
   "cell_type": "code",
   "source": "_ = ic(model.state_dict())",
   "id": "75a518bf4474a8ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | model.state_dict(): OrderedDict([('affine_transform.weight',\n",
      "                                        tensor([[ 0.4736,  0.6117,  0.4243,  0.2620,  0.9182,  0.3229,  0.8174,  0.6112,\n",
      "                                    0.3560,  0.2729,  0.9601, -0.0692,  0.5104,  0.6007,  0.5374,  0.6274,\n",
      "                                    0.9124,  0.9962,  1.1056,  0.3875, -0.0514,  0.7237,  0.1895,  0.6909,\n",
      "                                    0.7125,  0.6118,  0.9465,  0.6319,  0.0056,  0.1831,  0.4516,  0.3065,\n",
      "                                    0.4343,  0.4820,  0.1544,  0.6309,  0.2235,  0.1073,  0.8527,  0.2892,\n",
      "                                    0.4805,  0.7422,  0.6793,  0.2633, -0.0582,  0.3572,  0.2951,  0.2120,\n",
      "                                    0.3565,  0.4107,  0.1752,  0.7101,  0.1927,  0.5644,  0.6210,  0.8785,\n",
      "                                    0.3233,  0.2825,  1.0261,  0.0482,  0.9993,  0.5751,  0.7620,  0.6761,\n",
      "                                    0.5273,  0.2756,  0.8534,  0.5724,  0.6046,  0.1952,  0.1055,  0.5254,\n",
      "                                    0.3604,  0.6538,  0.2553,  0.9075,  0.3553,  0.2644,  0.2263,  0.0886,\n",
      "                                    0.8300,  0.5059,  0.1300,  0.1891,  0.1983,  0.7998,  0.3091,  0.0628,\n",
      "                                    0.9685,  0.7090,  0.8935,  0.1009,  0.3639,  0.9323,  0.1945,  0.7752,\n",
      "                                    0.2853,  0.8915,  0.6644,  0.0676]])),\n",
      "                                       ('affine_transform.bias', tensor([-0.2151]))])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model saving/loading is also straightforward:",
   "id": "bfed33c2a7d207ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.753629Z",
     "start_time": "2024-02-27T17:27:59.748978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving with `torch.save`\n",
    "th.save(\n",
    "    model.state_dict(), \"./model_ols.pt\"\n",
    ")  # Beware: we do not save `model` directly, but its `state_dict`!\n",
    "\n",
    "# Saving with `safetensors`\n",
    "safe_save_model(model, \"./model_ols_safe.pt\")"
   ],
   "id": "c487d57dc752d224",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:59.760199Z",
     "start_time": "2024-02-27T17:27:59.754925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading with `torch.load`\n",
    "model_loaded = LinearRegressor(in_features=P, out_features=1, bias=True)\n",
    "model_loaded.load_state_dict(th.load(\"./model_ols.pt\"))\n",
    "\n",
    "# Loading with `safetensors`\n",
    "model_loaded_safe = LinearRegressor(in_features=P, out_features=1, bias=True)\n",
    "_ = safe_load_model(model_loaded_safe, \"./model_ols_safe.pt\")"
   ],
   "id": "74d48d031700fbb7",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
