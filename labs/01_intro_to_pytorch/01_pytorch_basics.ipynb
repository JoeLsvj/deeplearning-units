{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63623daf7993ffb",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Introduction to `PyTorch` -- The basics\n",
    "\n",
    "[Deep Learning](https://dsai.units.it/index.php/courses/deep-learning/) Course @ [UniTS](https://portale.units.it/en), Spring 2024\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/emaballarin/deeplearning-units/blob/main/labs/01_intro_to_pytorch/01_pytorch_basics.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5c3d9f39d243f",
   "metadata": {},
   "source": [
    "### An aside on *programming*\n",
    "\n",
    "![image.png](https://ballarin.cc/code.jpg)\n",
    "<br><sub><sup>From <a href=\"https://www.commitstrip.com/en/2016/08/25/a-very-comprehensive-and-precise-spec/\">CommitStrip.com (August 25th, 2016)</a></sup></sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc12980e669bc69",
   "metadata": {},
   "source": [
    "### What is PyTorch?\n",
    "\n",
    "[PyTorch](https://pytorch.org/) (sometimes referred to simply as `torch`) is a Python/C++ library for:\n",
    "- Efficient numerical computing, with support for strong GPU acceleration & parallelism;\n",
    "- Automatic algorithmic differentiation (mainly in *reverse mode*, *tape-based*; but more recently also in *forward mode*);\n",
    "- Development of deep artificial neural network models (*a.k.a.* *deep learning*);\n",
    "\n",
    "It is also well integrated with the *scientific Python stack* (*i.e.* NumPy *& friends*).\n",
    "\n",
    "The flexibility of PyTorch and its *Pythonic* interfaces make it the most widely adopted framework for research and development, both in academia and industry (especially industrial *R&D*).\n",
    "\n",
    "For more info about PyTorch, you can have a look at the [official documentation](https://pytorch.org/docs/stable/index.html) or refer to [this book](https://bucket.ballarin.cc/books/EStevens_LAntiga_TViehmann_DeepLearningWithPyTorch.pdf).  \n",
    "For insights about the inner workings of *autodiff*, you can start exploring the topic from [this survey](https://arxiv.org/abs/1502.05767)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd284c13fc6ea5",
   "metadata": {},
   "source": [
    "### Preliminary infrastucture setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "a89c9b057229a895",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:24.170579Z",
     "start_time": "2024-02-27T17:27:22.735637Z"
    }
   },
   "source": [
    "!python -m pip install -q pip_install_if_missing"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1e489ddb0875803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:24.226666Z",
     "start_time": "2024-02-27T17:27:24.172234Z"
    }
   },
   "source": [
    "from piim import pip_install_if_missing\n",
    "\n",
    "pip_install_if_missing(\"icecream\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b4519a0e7269d06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:24.253320Z",
     "start_time": "2024-02-27T17:27:24.228194Z"
    }
   },
   "source": [
    "# Pretty printouts\n",
    "from icecream import ic\n",
    "\n",
    "ic.configureOutput(outputFunction=print)\n",
    "ic.configureOutput(prefix=\"    | \")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "5951ffbf0d96ab1",
   "metadata": {},
   "source": [
    "### Some imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "c13a187452f5e5d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.620449Z",
     "start_time": "2024-02-27T17:27:24.255383Z"
    }
   },
   "source": [
    "# It all begins with...\n",
    "import torch as th  # (or simply `import torch`)\n",
    "\n",
    "import numpy as np  # For comparison\n",
    "\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "\n",
    "# For type annotations\n",
    "from torch import Tensor\n",
    "from numpy.typing import NDArray\n",
    "from typing import Any"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c62bdd03270ec604",
   "metadata": {},
   "source": [
    "## Basic operation with `Tensor`s\n",
    "\n",
    "The main building block of PyTorch's linear algebra capabilities is the `Tensor` class. A torch `Tensor` is the (loose) equivalent of NumPy's `ndarray` and most of the functionalities are the same as in NumPy. In general, it is always possible to perform the same logical/mathematical operations typical of NumPy on torch `Tensor`s."
   ]
  },
  {
   "cell_type": "code",
   "id": "97639f7b5d4bf576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.641234Z",
     "start_time": "2024-02-27T17:27:25.621884Z"
    }
   },
   "source": [
    "# Creation of tensors\n",
    "x: Tensor = th.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y: NDArray[Any] = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "_ = ic(x)\n",
    "_ = ic(y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x: tensor([[1, 2, 3],\n",
      "                 [4, 5, 6]])\n",
      "    | y: array([[1, 2, 3],\n",
      "                [4, 5, 6]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "f1b2a61bdd00d36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.655732Z",
     "start_time": "2024-02-27T17:27:25.642700Z"
    }
   },
   "source": [
    "# Shapes and sizes\n",
    "_ = ic(x.size())\n",
    "_ = ic(x.shape)\n",
    "\n",
    "_ = ic(y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.size(): torch.Size([2, 3])\n",
      "    | x.shape: torch.Size([2, 3])\n",
      "    | y.shape: (2, 3)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e4614b76d7efde51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.666900Z",
     "start_time": "2024-02-27T17:27:25.657291Z"
    }
   },
   "source": [
    "# (d)types\n",
    "_ = ic(x.dtype)\n",
    "_ = ic(y.dtype)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.dtype: torch.int64\n",
      "    | y.dtype: dtype('int64')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "2e5ece1b03e8661",
   "metadata": {},
   "source": [
    "You can convert the dtype of a tensor by using `Tensor` methods `float()`, `int()`, etc.... or by using the `to(dtype=...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9b240f23dd9d09d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.672273Z",
     "start_time": "2024-02-27T17:27:25.667979Z"
    }
   },
   "source": [
    "print(\"dtype of x before casting:\", x.dtype)\n",
    "x: Tensor = x.float()\n",
    "print(\"dtype of x after casting:\", x.dtype)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of x before casting: torch.int64\n",
      "dtype of x after casting: torch.float32\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3138ba05fa45f65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.677701Z",
     "start_time": "2024-02-27T17:27:25.673324Z"
    }
   },
   "source": [
    "# Or with more granular control\n",
    "x: Tensor = x.to(dtype=th.float16)\n",
    "print(\"dtype of x:\", x.dtype)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of x: torch.float16\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "e5a985a2d902d1b4",
   "metadata": {},
   "source": [
    "Note that you can build a tensor through the constructor `th.Tensor` (as opposed to `torch.tensor`, mind the capitalisation!). In this case, since `th.Tensor` is an alias for `th.FloatTensor`, the tensor you create will have type `th.float32`.\n",
    "\n",
    "More info on `Tensor` data types: [here](https://pytorch.org/docs/stable/tensors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785522c0da9c33e",
   "metadata": {},
   "source": [
    "You can create random tensors, just like you create random arrays in `NumPy`:"
   ]
  },
  {
   "cell_type": "code",
   "id": "434a3b9928c68260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.692605Z",
     "start_time": "2024-02-27T17:27:25.679793Z"
    }
   },
   "source": [
    "x: Tensor = th.rand(\n",
    "    2, 3, 2\n",
    ")  # also accepts a list or tuple of integers (e.g. th.rand([2, 3, 2]), etc...)\n",
    "y: NDArray[Any] = np.random.rand(2, 3, 2)\n",
    "\n",
    "_ = ic(x)\n",
    "_ = ic(y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x: tensor([[[0.0566, 0.6746],\n",
      "                  [0.1083, 0.8392],\n",
      "                  [0.8146, 0.7506]],\n",
      "         \n",
      "                 [[0.4512, 0.5809],\n",
      "                  [0.4778, 0.6406],\n",
      "                  [0.2304, 0.5144]]])\n",
      "    | y: array([[[0.97096942, 0.64125227],\n",
      "                 [0.83194714, 0.54701953],\n",
      "                 [0.66671112, 0.78667349]],\n",
      "         \n",
      "                [[0.76515973, 0.8957745 ],\n",
      "                 [0.8366769 , 0.03034972],\n",
      "                 [0.87956078, 0.22523813]]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "6ee024b5f559f3d6",
   "metadata": {},
   "source": [
    "Tensor slicing works like in NumPy, by means of square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "id": "28a6f0f292765b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.701186Z",
     "start_time": "2024-02-27T17:27:25.693739Z"
    }
   },
   "source": [
    "x: Tensor = th.rand(2, 3, 2)\n",
    "_ = ic(x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x: tensor([[[0.5097, 0.4869],\n",
      "                  [0.7228, 0.8996],\n",
      "                  [0.0305, 0.4536]],\n",
      "         \n",
      "                 [[0.6089, 0.7877],\n",
      "                  [0.3264, 0.4518],\n",
      "                  [0.8162, 0.9160]]])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "c764ebdbaf9b3415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.717571Z",
     "start_time": "2024-02-27T17:27:25.702320Z"
    }
   },
   "source": [
    "_ = ic(x[0, 1, 1])\n",
    "\n",
    "_ = ic(x[0, 1:, 1])\n",
    "\n",
    "_ = ic(x[:, ::2, :])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x[0, 1, 1]: tensor(0.8996)\n",
      "    | x[0, 1:, 1]: tensor([0.8996, 0.4536])\n",
      "    | x[:, ::2, :]: tensor([[[0.5097, 0.4869],\n",
      "                             [0.0305, 0.4536]],\n",
      "                    \n",
      "                            [[0.6089, 0.7877],\n",
      "                             [0.8162, 0.9160]]])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "f3d8cb022646a3af",
   "metadata": {},
   "source": [
    "Beware of 0-dimensional vs 1-dimensional tensors:"
   ]
  },
  {
   "cell_type": "code",
   "id": "662aa0385681e0d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.729574Z",
     "start_time": "2024-02-27T17:27:25.718562Z"
    }
   },
   "source": [
    "_ = ic(x[0, 1, 1].shape)\n",
    "\n",
    "_ = ic(th.tensor(3.14).shape)\n",
    "\n",
    "_ = ic(th.tensor([3.14]).shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x[0, 1, 1].shape: torch.Size([])\n",
      "    | th.tensor(3.14).shape: torch.Size([])\n",
      "    | th.tensor([3.14]).shape: torch.Size([1])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "8ccb4d1849e1580",
   "metadata": {},
   "source": [
    "You can use the `numel` method to get the number of elements (*i.e.* scalars) in a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a7b7b626877769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.744066Z",
     "start_time": "2024-02-27T17:27:25.730815Z"
    }
   },
   "source": [
    "# Use of `numel`\n",
    "_ = ic(x.numel())\n",
    "\n",
    "_ = ic(th.tensor(3.14).numel())\n",
    "\n",
    "_ = ic(th.tensor([3.14]).numel())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.numel(): 12\n",
      "    | th.tensor(3.14).numel(): 1\n",
      "    | th.tensor([3.14]).numel(): 1\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "2f1a9609c7f2afaa",
   "metadata": {},
   "source": [
    "### Tensor reshaping\n",
    "\n",
    "Changing the shape of a tensor can be a crucial operation.  \n",
    "To have an idea of its application, just think of `RGB` images. These may be represented as $3\\times \\text{H}\\times \\text{W}$ tensors, where $\\text{H}$ and $\\text{W}$ stand for height and width of the image (in number of pixels). It is often needed to look at an image as a flattened (1D) vector of pixels:"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd6ac8dd457a9acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.758759Z",
     "start_time": "2024-02-27T17:27:25.745157Z"
    }
   },
   "source": [
    "img: Tensor = th.stack(\n",
    "    tensors=(th.ones(8, 8), th.zeros(8, 8), th.ones(8, 8) / 2), dim=0\n",
    ")\n",
    "\n",
    "# Note that reshaping is not in place, so this call does not change the actual shape of img!\n",
    "img.reshape(3, 64)\n",
    "\n",
    "_ = ic(img.shape)\n",
    "\n",
    "img2: Tensor = img.reshape(3, 64)\n",
    "_ = ic(img2.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | img.shape: torch.Size([3, 8, 8])\n",
      "    | img2.shape: torch.Size([3, 64])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "bd9a701a0946bf8d",
   "metadata": {},
   "source": [
    "When you reshape a tensor, you can leave one dimension unspecified (using `-1`, at most **once**), as it will be inferred automatically."
   ]
  },
  {
   "cell_type": "code",
   "id": "6bb1acba5505f6bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.768677Z",
     "start_time": "2024-02-27T17:27:25.759848Z"
    }
   },
   "source": [
    "img_inferred: Tensor = img.reshape(3, -1)\n",
    "_ = ic(img_inferred.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | img_inferred.shape: torch.Size([3, 64])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "ecb2c29f2d8cf86d",
   "metadata": {},
   "source": [
    "Let's print the \"image\" (it should be a **uniformly pink** square)..."
   ]
  },
  {
   "cell_type": "code",
   "id": "795fe6fda36d64a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.772856Z",
     "start_time": "2024-02-27T17:27:25.769698Z"
    }
   },
   "source": [
    "# plt.imshow(img)\n",
    "# It errors with \"TypeError: Invalid shape (3, 8, 8) for image data\""
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "725714eabb45ffe8",
   "metadata": {},
   "source": [
    "In fact, `matplotlib` expects arrays in the $\\text{H}\\times \\text{W}\\times \\text{C}$, whereas `PyTorch` uses the $\\text{C}\\times \\text{H}\\times \\text{W}$ format."
   ]
  },
  {
   "cell_type": "code",
   "id": "734c845e148dccd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.897949Z",
     "start_time": "2024-02-27T17:27:25.773806Z"
    }
   },
   "source": [
    "new_img: Tensor = img.reshape(8, 8, 3)\n",
    "_ = plt.imshow(new_img.numpy())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "dfb9faa6a2579777",
   "metadata": {},
   "source": [
    "**Why is it not pink?** ðŸ¤”\n",
    "\n",
    "`reshape` only modifies the shape of a `Tensor`, without changing the way data are stored in memory. The \"right\" way to change the order of dimensions is to use the `permute` method, which reorders dimensions in-memory.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Difference between:\n",
    "- `view`: operations on contiguous memory;\n",
    "- `reshape`: operations on (non-)contiguous memory, using `view` wherever possible;\n",
    "- `permute`: explicit reordering of dimensions and memory;\n",
    "- `.contiguous()`: ensure that the tensor is stored in contiguous memory (copying if necessary), with no other modification."
   ]
  },
  {
   "cell_type": "code",
   "id": "7dffd4b33839ff2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:25.990279Z",
     "start_time": "2024-02-27T17:27:25.899336Z"
    }
   },
   "source": [
    "new_img: Tensor = img.permute(1, 2, 0)\n",
    "_ = plt.imshow(new_img.numpy())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "2e969bbb6ca39d9e",
   "metadata": {},
   "source": [
    "Another memory-contiguity quirk..."
   ]
  },
  {
   "cell_type": "code",
   "id": "fd30df1999ac1076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.005510Z",
     "start_time": "2024-02-27T17:27:25.991710Z"
    }
   },
   "source": [
    "z: Tensor = th.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y: Tensor = z.t()  # Transposition does not guarantee memory contiguity!\n",
    "_ = ic(y.size())\n",
    "# _ = ic(y.view(6))   # It errors, as memory is not contiguously-addressed!\n",
    "_ = ic(y.contiguous().view(6))  # This works! Or use `reshape` instead of `view`."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | y.size(): torch.Size([3, 2])\n",
      "    | y.contiguous().view(6): tensor([1, 4, 2, 5, 3, 6])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "c30a4d67ced398cc",
   "metadata": {},
   "source": [
    "### Arithmetic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dd815d30d9b0d",
   "metadata": {},
   "source": [
    "As in NumPy, PyTorch supports all the basic arithmetic operations. By default, these operations are performed **element-wise**."
   ]
  },
  {
   "cell_type": "code",
   "id": "3abfb0705df5f798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.023919Z",
     "start_time": "2024-02-27T17:27:26.006597Z"
    }
   },
   "source": [
    "x: Tensor = th.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "y: Tensor = th.tensor([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]])\n",
    "\n",
    "_ = ic(x + y)\n",
    "_ = ic(x / y)\n",
    "\n",
    "_ = ic(x**2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x + y: tensor([[ 8., 10., 12.],\n",
      "                     [14., 16., 18.]])\n",
      "    | x / y: tensor([[0.1429, 0.2500, 0.3333],\n",
      "                     [0.4000, 0.4545, 0.5000]])\n",
      "    | x**2: tensor([[ 1.,  4.,  9.],\n",
      "                    [16., 25., 36.]])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "ad7fe4034ebbf74f",
   "metadata": {},
   "source": [
    "### Linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d5ae0694ec418",
   "metadata": {},
   "source": [
    "An operation we will frequently perform in Deep Learning (often under the hood, though) is **matrix multiplication**. In `torch`, it can be done in many equivalent ways:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fa4c490159ecfa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.041123Z",
     "start_time": "2024-02-27T17:27:26.025085Z"
    }
   },
   "source": [
    "x: Tensor = th.rand(4, 5)\n",
    "y: Tensor = x.T  # matrix transposition; also .t()\n",
    "\n",
    "# All the same!\n",
    "_ = ic(x @ y)\n",
    "_ = ic(x.matmul(y))\n",
    "_ = ic(th.matmul(x, y))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x @ y: tensor([[2.7589, 1.9781, 1.8481, 1.6978],\n",
      "                     [1.9781, 2.0202, 1.0229, 1.4264],\n",
      "                     [1.8481, 1.0229, 1.7246, 0.9895],\n",
      "                     [1.6978, 1.4264, 0.9895, 2.0342]])\n",
      "    | x.matmul(y): tensor([[2.7589, 1.9781, 1.8481, 1.6978],\n",
      "                           [1.9781, 2.0202, 1.0229, 1.4264],\n",
      "                           [1.8481, 1.0229, 1.7246, 0.9895],\n",
      "                           [1.6978, 1.4264, 0.9895, 2.0342]])\n",
      "    | th.matmul(x, y): tensor([[2.7589, 1.9781, 1.8481, 1.6978],\n",
      "                               [1.9781, 2.0202, 1.0229, 1.4264],\n",
      "                               [1.8481, 1.0229, 1.7246, 0.9895],\n",
      "                               [1.6978, 1.4264, 0.9895, 2.0342]])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "fb8e46bbc50e4951",
   "metadata": {},
   "source": [
    "Please note that the operator for matrix multiplication is `@`, not `*`, which indicates the Hadamard (element-wise) product instead."
   ]
  },
  {
   "cell_type": "code",
   "id": "3ce30c08c7bd0531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.049889Z",
     "start_time": "2024-02-27T17:27:26.042326Z"
    }
   },
   "source": [
    "_ = ic(x * x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x * x: tensor([[5.3017e-01, 4.9619e-01, 4.9818e-01, 3.8894e-01, 8.4542e-01],\n",
      "                     [9.3142e-01, 3.6632e-01, 5.7612e-01, 1.3856e-01, 7.7880e-03],\n",
      "                     [1.5409e-01, 6.3461e-03, 6.2776e-02, 7.9258e-01, 7.0881e-01],\n",
      "                     [2.5537e-03, 9.9025e-01, 3.8834e-01, 6.5274e-01, 3.1501e-04]])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "e24c72d548e9d212",
   "metadata": {},
   "source": [
    "Likewise, the power operator `**` is element-wise, not matrix-wise!"
   ]
  },
  {
   "cell_type": "code",
   "id": "db0ec5714802d407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.065761Z",
     "start_time": "2024-02-27T17:27:26.051418Z"
    }
   },
   "source": [
    "x: Tensor = th.rand(4, 4)\n",
    "\n",
    "_ = ic(x**2)  # or x.pow(2)\n",
    "_ = ic(x @ x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x**2: tensor([[0.0105, 0.1844, 0.6043, 0.0879],\n",
      "                    [0.0447, 0.6765, 0.8923, 0.6324],\n",
      "                    [0.5708, 0.0181, 0.2970, 0.6403],\n",
      "                    [0.0261, 0.7873, 0.9214, 0.9814]])\n",
      "    | x @ x: tensor([[0.7366, 0.7651, 1.1937, 1.2877],\n",
      "                     [1.0378, 1.6002, 2.2194, 2.2604],\n",
      "                     [0.6472, 1.2187, 1.7797, 1.5600],\n",
      "                     [1.0895, 1.8076, 2.4380, 2.5030]])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "5b63de42591a45cd",
   "metadata": {},
   "source": [
    "As in NumPy, there exists a `dot` function to compute the scalar product between vectors. Note that, differently from NumPy, in `torch` this is not equivalent to matrix multiplication, and works only with 1D vectors!"
   ]
  },
  {
   "cell_type": "code",
   "id": "e96c16d04d6a529d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.074159Z",
     "start_time": "2024-02-27T17:27:26.066874Z"
    }
   },
   "source": [
    "v1: Tensor = x[0, :]\n",
    "v2: Tensor = x[1, :]\n",
    "\n",
    "_ = ic(th.dot(v1, v2))\n",
    "\n",
    "# _ = ic(th.dot(x, x)) # It errors!"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | th.dot(v1, v2): tensor(1.3450)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "7e408fb9bfbe60d0",
   "metadata": {},
   "source": [
    "### Reduction operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdb43ba5e7b5e5",
   "metadata": {},
   "source": [
    "You can easily compute statistics of tensors (or general *reduction operations*, *e.g.* sum, mean, max, min, stddev... of the elements) by either using `torch` functions, or same-named `Tensor` methods:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b1ee686e6432164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.081316Z",
     "start_time": "2024-02-27T17:27:26.075102Z"
    }
   },
   "source": [
    "x: Tensor = th.rand(2, 3, 2)\n",
    "_ = ic(x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x: tensor([[[0.1467, 0.3975],\n",
      "                  [0.7459, 0.3524],\n",
      "                  [0.6929, 0.5012]],\n",
      "         \n",
      "                 [[0.6587, 0.7164],\n",
      "                  [0.9142, 0.3537],\n",
      "                  [0.6543, 0.7198]]])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "dbd9496745d42747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.097087Z",
     "start_time": "2024-02-27T17:27:26.082885Z"
    }
   },
   "source": [
    "_ = ic(x.sum())\n",
    "_ = ic(th.sum(x))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.sum(): tensor(6.8537)\n",
      "    | th.sum(x): tensor(6.8537)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "2cb8f56e5b87e6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.111556Z",
     "start_time": "2024-02-27T17:27:26.100427Z"
    }
   },
   "source": [
    "_ = ic(x.mean())\n",
    "_ = ic(th.mean(x))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.mean(): tensor(0.5711)\n",
      "    | th.mean(x): tensor(0.5711)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "244fb20d6a8e4309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.121556Z",
     "start_time": "2024-02-27T17:27:26.112547Z"
    }
   },
   "source": [
    "_ = ic(x.argmin())\n",
    "_ = ic(th.min(x))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.argmin(): tensor(0)\n",
      "    | th.min(x): tensor(0.1467)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "bdea860a3cac791e",
   "metadata": {},
   "source": [
    "It is sometimes useful to specify one or more dimensions to reduce (along which you want to perform your operations):"
   ]
  },
  {
   "cell_type": "code",
   "id": "98981f2f54bc4ab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.140018Z",
     "start_time": "2024-02-27T17:27:26.122632Z"
    }
   },
   "source": [
    "_ = ic(x.mean(dim=0))\n",
    "_ = ic(x.argmax(dim=1))\n",
    "_ = ic(x.sum(dim=(0, 1)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x.mean(dim=0): tensor([[0.4027, 0.5569],\n",
      "                             [0.8300, 0.3531],\n",
      "                             [0.6736, 0.6105]])\n",
      "    | x.argmax(dim=1): tensor([[1, 2],\n",
      "                               [1, 2]])\n",
      "    | x.sum(dim=(0, 1)): tensor([3.8127, 3.0410])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "6b582a64809934c",
   "metadata": {},
   "source": [
    "## GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254fc558fe7d929",
   "metadata": {},
   "source": [
    "PyTorch is designed to work seamlessly with GPUs (or hardware accelerators in general). You can move tensors to the GPU by using the `cuda` method, or the `to` method (for general devices, including CUDA, CPU, and others)."
   ]
  },
  {
   "cell_type": "code",
   "id": "8723cfa6ed55123c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:26.152950Z",
     "start_time": "2024-02-27T17:27:26.141177Z"
    }
   },
   "source": [
    "x: Tensor = th.rand(2, 3)\n",
    "_ = ic(x)\n",
    "_ = ic(x.device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x: tensor([[0.3876, 0.8396, 0.3117],\n",
      "                 [0.8634, 0.3876, 0.0785]])\n",
      "    | x.device: device(type='cpu')\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "d3c64c2c7d1ccff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:28.117451Z",
     "start_time": "2024-02-27T17:27:26.154040Z"
    }
   },
   "source": [
    "x: Tensor = x.to(device=\"cuda\")  # or x.cuda()\n",
    "_ = ic(x)\n",
    "_ = ic(x.device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | x: tensor([[0.3876, 0.8396, 0.3117],\n",
      "                 [0.8634, 0.3876, 0.0785]], device='cuda:0')\n",
      "    | x.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "e96ca56cedadd690",
   "metadata": {},
   "source": [
    "#### Why GPUs?\n",
    "\n",
    "Let's see..."
   ]
  },
  {
   "cell_type": "code",
   "id": "904c336552e1adef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:28.147773Z",
     "start_time": "2024-02-27T17:27:28.118720Z"
    }
   },
   "source": [
    "a: Tensor = th.rand(1000, 1000)\n",
    "b: Tensor = th.rand(1000, 1000)\n",
    "_ = ic(th.matmul(a, b))  # Warmup (does not cache the result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | th.matmul(a, b): tensor([[248.5054, 244.0699, 260.0825,  ..., 245.6781, 247.1087, 251.7783],\n",
      "                               [247.3436, 240.7231, 246.9280,  ..., 239.9678, 239.5166, 254.0617],\n",
      "                               [254.6329, 253.6068, 262.7984,  ..., 255.8509, 251.1407, 263.1866],\n",
      "                               ...,\n",
      "                               [246.3882, 237.8904, 248.6055,  ..., 239.7312, 239.7239, 246.7213],\n",
      "                               [252.1723, 247.4497, 258.6422,  ..., 249.1569, 246.3595, 256.9336],\n",
      "                               [253.2659, 247.6227, 252.1317,  ..., 243.6900, 248.9021, 250.1017]])\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "61ff7821cd9dfbbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:34.120254Z",
     "start_time": "2024-02-27T17:27:28.149068Z"
    }
   },
   "source": [
    "# On CPU\n",
    "for _ in range(1000):\n",
    "    r: Tensor = th.matmul(a, b)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "aabab6797529ef75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:34.203858Z",
     "start_time": "2024-02-27T17:27:34.122046Z"
    }
   },
   "source": [
    "a_cuda: Tensor = a.cuda()\n",
    "b_cuda: Tensor = b.cuda()\n",
    "_ = ic(th.matmul(a_cuda, b_cuda))  # Warmup (does not cache the result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | th.matmul(a_cuda, b_cuda): tensor([[248.5053, 244.0698, 260.0825,  ..., 245.6782, 247.1088, 251.7783],\n",
      "                                         [247.3437, 240.7231, 246.9280,  ..., 239.9677, 239.5165, 254.0617],\n",
      "                                         [254.6329, 253.6068, 262.7984,  ..., 255.8509, 251.1407, 263.1865],\n",
      "                                         ...,\n",
      "                                         [246.3882, 237.8903, 248.6055,  ..., 239.7313, 239.7238, 246.7215],\n",
      "                                         [252.1723, 247.4496, 258.6422,  ..., 249.1570, 246.3595, 256.9336],\n",
      "                                         [253.2659, 247.6227, 252.1317,  ..., 243.6899, 248.9020, 250.1017]],\n",
      "                                        device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "c1f257cd38490bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T17:27:34.505966Z",
     "start_time": "2024-02-27T17:27:34.205271Z"
    }
   },
   "source": [
    "# On GPU\n",
    "for _ in range(1000):\n",
    "    r: Tensor = th.matmul(a_cuda, b_cuda)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "317148b2787e7b29",
   "metadata": {},
   "source": [
    "A >12x speedup, just by moving the computation to the GPU!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
