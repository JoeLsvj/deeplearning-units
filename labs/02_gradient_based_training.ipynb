{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e6e08a7368590a",
   "metadata": {},
   "source": [
    "# üßëüèª‚Äçüíª How to train a (deep learning) model in PyTorch\n",
    "\n",
    "[Deep Learning](https://dsai.units.it/index.php/courses/deep-learning/) Course @ [UniTS](https://portale.units.it/en), Spring 2024\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/emaballarin/deeplearning-units/blob/main/labs/02_gradient_based_training.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>  <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/emaballarin/deeplearning-units/blob/main/labs/02_gradient_based_training.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac3ac454a4e440",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![itstraining.png](https://i.redd.it/5cjdqxcg07k11.png)\n",
    "<br><sub><sup>From <a href=\"https://www.reddit.com/r/ProgrammerHumor/comments/9cu51a/shamelessly_stolen_from_xkcd_credit_where_is_due/\">/r/ProgrammerHumor (September 8th, 2018)</a></sup></sub>\n",
    "\n",
    "In today's lab, we will learn how to train a model in PyTorch (*i.e.* a `torch.nn.Module`). Most of the future laboratories will build upon this one, since training a model is a crucial part of deep learning.  \n",
    "\n",
    "Just to be extra clear: here, by *training a model* we mean the process of finding the approximately-best parameters for a model, given a task to be solved, usually some data, and eventually some external constraint (*e.g.* time, compute availability, etc...). This is done by minimizing a loss function, which measures how well the model is performing, usually by first-order methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b899a5ed39229",
   "metadata": {},
   "source": [
    "### Preliminary infrastucture setup\n",
    "\n",
    "Nothing new here, just the usual cloud-aware setup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cce0b2f377ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:50.566208Z",
     "start_time": "2024-04-08T12:43:50.559760Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:47.854021Z",
     "iopub.status.busy": "2024-04-08T12:56:47.853472Z",
     "iopub.status.idle": "2024-04-08T12:56:47.863752Z",
     "shell.execute_reply": "2024-04-08T12:56:47.863239Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FOLDERNAME: str = \"deeplearning_units_2024\"\n",
    "try:\n",
    "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "        # noinspection PyUnresolvedReferences\n",
    "        from google.colab import drive\n",
    "\n",
    "        drive.mount(BASEPATH := \"/content/drive\")\n",
    "        os.makedirs(FULLPATH := BASEPATH + \"/MyDrive/\" + FOLDERNAME, exist_ok=True)\n",
    "    elif os.getenv(\"KAGGLE_CONTAINER_NAME\"):\n",
    "        os.makedirs(FULLPATH := \"/kaggle/working/\" + FOLDERNAME, exist_ok=True)\n",
    "    else:\n",
    "        os.makedirs(FULLPATH := \"./\" + FOLDERNAME, exist_ok=True)\n",
    "    os.chdir(FULLPATH)\n",
    "except (ModuleNotFoundError, FileExistsError, FileNotFoundError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27188a59391dcf0",
   "metadata": {},
   "source": [
    "### The imports for the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64f7d1efb5a589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:59.085337Z",
     "start_time": "2024-04-08T12:43:50.590571Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:47.865986Z",
     "iopub.status.busy": "2024-04-08T12:56:47.865704Z",
     "iopub.status.idle": "2024-04-08T12:56:52.254908Z",
     "shell.execute_reply": "2024-04-08T12:56:52.254186Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from ebtorch.nn.utils import eval_model_on_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from typing import List, Union, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df9795d972ba1",
   "metadata": {},
   "source": [
    "## The *typical* model training *pipeline*\n",
    "\n",
    "> *`Model training` est divisus in partes tres*:\n",
    "> - the **task** (which eventually includes actual **data**),\n",
    "> - the **model** (and associated **loss function**),\n",
    "> - the **optimization process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3dd6aff0cf774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:59.090253Z",
     "start_time": "2024-04-08T12:43:59.086835Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:52.258643Z",
     "iopub.status.busy": "2024-04-08T12:56:52.257886Z",
     "iopub.status.idle": "2024-04-08T12:56:52.264281Z",
     "shell.execute_reply": "2024-04-08T12:56:52.263766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful hyperparameters\n",
    "DEVICE_AUTODETECT: bool = True\n",
    "TRAIN_BATCH_SIZE: int = 128\n",
    "TEST_BATCH_SIZE: int = int(1e4)\n",
    "EPOCHS: int = 10\n",
    "CRITERION: Union[th.nn.Module, Callable[[th.Tensor], th.Tensor]] = (\n",
    "    th.nn.CrossEntropyLoss()\n",
    ")\n",
    "LR: float = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d06d56a0b7e1a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:00.650412Z",
     "start_time": "2024-04-08T12:43:59.091221Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:52.266435Z",
     "iopub.status.busy": "2024-04-08T12:56:52.266245Z",
     "iopub.status.idle": "2024-04-08T12:56:53.670224Z",
     "shell.execute_reply": "2024-04-08T12:56:53.669545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's detect and select the most appropriate device\n",
    "# (adapt it to your specific hardware needs: mps, tpu, ...)\n",
    "device: th.device = th.device(\n",
    "    \"cuda\" if th.cuda.is_available() and DEVICE_AUTODETECT else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc498887faf7c",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "Training a deep learning model almost always requires some data. Even though, in principle, nothing prevents you from carrying around data in `torch.Tensor`s, PyTorch provides two handy classes to handle data in a more structured way.\n",
    "\n",
    "They are `torch.utils.data.Dataset` and `torch.utils.data.DataLoader`. The former constitutes an abstraction over the actual dataset, composed of the atomic data-units seen by the model during training; the latter is a wrapper around the `Dataset`, which defines how data are accessed, and allows for parallel data loading, shuffling, and other useful features.\n",
    "\n",
    "Unless you have very stringent reasons to do otherwise, you should always use these classes to handle your data.\n",
    "\n",
    "In case you need to implement your own `Dataset`, remember that it should inherit from `torch.utils.data.Dataset` and implement the `__len__` and `__getitem__` methods. More info about custom `Dataset`s can be found [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) and [here](https://pytorch.org/docs/stable/data.html).\n",
    "\n",
    "In this lab, we will use the famous `MNIST` dataset, which is composed of labelled handwritten digits. It is a very common benchmark dataset, so that it is directly included as a `Dataset` in the `torchvision` package.\n",
    "\n",
    "The task will be, indeed, handwritten digit classification.\n",
    "\n",
    "**Remark:** The `transforms` we are using are meant to convert the images into `torch.Tensor`s (`ToTensor()`) and to normalize the images to have 0 mean and standard deviation 1 (`Normalize(mean, stddev)`).\n",
    "\n",
    "**Remark:** The `batch_size` argument allows us to setup mini-batched model training. If we define a batch_size of 128, it means that at each training step the network is fed with 128 datapoints from our dataset, on which an optimization step will be performed. The choice of batch size may dramatically affect the training process (all other hyperparameters being constant), and even though there is still debate around whether it should be treated as a tunable hyperparameter, it balances memory efficiency and effective gradient noise. Generally speaking, [one should aim for the highest batch size that fits in memory](https://arxiv.org/abs/1811.03600), and then tune optimization parameters to adapt the learning process as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab95e22e383d7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:00.946653Z",
     "start_time": "2024-04-08T12:44:00.652428Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:53.672305Z",
     "iopub.status.busy": "2024-04-08T12:56:53.672130Z",
     "iopub.status.idle": "2024-04-08T12:56:57.351762Z",
     "shell.execute_reply": "2024-04-08T12:56:57.350669Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "os.makedirs(\"./data/\", exist_ok=True)\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=mnist_transforms, download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=mnist_transforms, download=True\n",
    ")\n",
    "\n",
    "train_loader: DataLoader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader: DataLoader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148b88e198e4f43",
   "metadata": {},
   "source": [
    "Let's have a look at the data we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e0801b4ae3eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.196745Z",
     "start_time": "2024-04-08T12:44:00.949822Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.356677Z",
     "iopub.status.busy": "2024-04-08T12:56:57.355840Z",
     "iopub.status.idle": "2024-04-08T12:56:57.572647Z",
     "shell.execute_reply": "2024-04-08T12:56:57.571618Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img) -> None:\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(npimg, axes=(1, 2, 0)))\n",
    "\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = train_loader.__iter__()\n",
    "images, labels = dataiter.__next__()\n",
    "\n",
    "# Show grid of images\n",
    "imshow(tv.utils.make_grid(images[: 8 * 4], normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59138d9079708a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.205486Z",
     "start_time": "2024-04-08T12:44:01.199232Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.574932Z",
     "iopub.status.busy": "2024-04-08T12:56:57.574743Z",
     "iopub.status.idle": "2024-04-08T12:56:57.579537Z",
     "shell.execute_reply": "2024-04-08T12:56:57.578732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see the associated labels\n",
    "print(f\"Labels: {labels[:8*4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723715da7adc69c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.581818Z",
     "iopub.status.busy": "2024-04-08T12:56:57.581633Z",
     "iopub.status.idle": "2024-04-08T12:56:57.584967Z",
     "shell.execute_reply": "2024-04-08T12:56:57.584205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's see the shape of the images\n",
    "print(f\"Images shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cce80e4da566f3",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "In `PyTorch`, we usually define a model by subclassing the `nn.Module` class and defining the `forward` method. The `forward` method is where we define the *computation* that happens at every *forward pass* of the model.\n",
    "\n",
    "Except for extreme corner-cases, the backward pass is automatically defined by `PyTorch` *autograd* system and gradients are obtained efficiently whenever needed.\n",
    "\n",
    "`PyTorch` modules are *transparent* with respect to batch sizes, i.e. we can use the same model to process a single sample or a batch of samples, without worrying about the exact batch size.\n",
    "\n",
    "Let's define a simple **1-hidden-layer multilayer perceptron** as an example. Apart from specific peculiarities, the rest of the notebook should be general enough to be applied to any model.\n",
    "\n",
    "In our case, the MLP will have a hidden layer of 128 neurons, with ReLU activations. The input layer has size is 784 (since our images are 1x28x28), and the output layer has 10 (since we have 10 possible classes).\n",
    "\n",
    "The ReLU is the Rectified Linear Unit, defined as:\n",
    "$$\n",
    "\\text{ReLU}(x) = \\max(0, x) = \\begin{cases}x & \\text{ if } x \\geq 0 \\\\0 & \\text{ if } x < 0\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527070e4daf068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.223486Z",
     "start_time": "2024-04-08T12:44:01.215588Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.586902Z",
     "iopub.status.busy": "2024-04-08T12:56:57.586646Z",
     "iopub.status.idle": "2024-04-08T12:56:57.591032Z",
     "shell.execute_reply": "2024-04-08T12:56:57.590514Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyMLP(th.nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Affine linear transform sub-module: input-to-hidden\n",
    "        self.fc1: th.nn.Module = th.nn.Linear(\n",
    "            in_features=input_size, out_features=hidden_size, bias=True\n",
    "        )\n",
    "\n",
    "        # Affine linear transform sub-module: hidden-to-output\n",
    "        self.fc2: th.nn.Module = th.nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x_: th.Tensor) -> th.Tensor:\n",
    "        x_ = th.flatten(x_, start_dim=1)  # Keep batch dimension, flatten the rest\n",
    "        # I.e.: (N, C, H, W) -> (N, C*H*W)\n",
    "\n",
    "        x_ = self.fc1(x_)  # Apply first linear transformation\n",
    "        x_ = th.nn.functional.relu(x_)  # Apply ReLU activation\n",
    "        # Activation functions are usually applied elementwise\n",
    "\n",
    "        x_ = self.fc2(x_)  # Apply second linear transformation\n",
    "\n",
    "        # N.B.: outputs are [-inf, +inf]; e.g. to be used as logits\n",
    "        return x_\n",
    "\n",
    "\n",
    "# But we won't use this model in this notebook, so...\n",
    "del MyMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a9aeaf3aa1d4c",
   "metadata": {},
   "source": [
    "By sacrificing some flexibility in the definition of the `forward` pass, one could also define a model via the `torch.Sequential` API, which is much more compact. The `nn.` elements usually mirror their equivalent `torch.nn.functional.` counterparts.\n",
    "\n",
    "From the computational viewpoint, the approaches are almost identical. Sometimes, `nn.Sequential` objects support more built-in abstractions, given their stricter structure (*e.g.* in-order network layer iteration).\n",
    "\n",
    "In our case, the same model is easily translated into a `Sequential` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ecf6c75c30dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.231295Z",
     "start_time": "2024-04-08T12:44:01.226273Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.592867Z",
     "iopub.status.busy": "2024-04-08T12:56:57.592637Z",
     "iopub.status.idle": "2024-04-08T12:56:57.596117Z",
     "shell.execute_reply": "2024-04-08T12:56:57.595656Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_myseqmlp(\n",
    "    input_size: int, hidden_size: int, output_size: int\n",
    ") -> th.nn.Sequential:\n",
    "    return th.nn.Sequential(\n",
    "        th.nn.Flatten(start_dim=1),  # Flatten the input\n",
    "        th.nn.Linear(\n",
    "            in_features=input_size, out_features=hidden_size, bias=True\n",
    "        ),  # First linear transformation\n",
    "        th.nn.ReLU(),  # ReLU activation\n",
    "        th.nn.Linear(\n",
    "            hidden_size, output_size, bias=True\n",
    "        ),  # Second linear transformation\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f8e714296d8c9",
   "metadata": {},
   "source": [
    "#### The loss function\n",
    "\n",
    "A crucial element needed to train any model is the *loss function*, *i.e.* a function that quantifies how well our model solves our task on some given data. In the context of Deep Learning, a loss function should be differentiable (at least in the algorithmic sense) *w.r.t.* the learnable parameters of the model.\n",
    "\n",
    "PyTorch already provides many commonly-used loss functions, which can be found in the `torch.nn` module (as `nn.Module`s) or in the `torch.nn.functional` module (as functions). You can find a list of the former in the [official documentation](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "You can also define your own custom loss function. It should at least be callable and return a `torch.Tensor`. As long as you create it using built-in `torch` functions, it should also be differentiable... and you are good to go!\n",
    "\n",
    "As an example, you could build your own MSE loss like this (but please, do yourself a favour and use that already - and more efficiently - implemented in PyTorch!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba8b9d20030485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.239657Z",
     "start_time": "2024-04-08T12:44:01.235722Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.598199Z",
     "iopub.status.busy": "2024-04-08T12:56:57.597834Z",
     "iopub.status.idle": "2024-04-08T12:56:57.600632Z",
     "shell.execute_reply": "2024-04-08T12:56:57.600044Z"
    }
   },
   "outputs": [],
   "source": [
    "def mseloss(output: th.Tensor, target: th.Tensor) -> th.Tensor:\n",
    "    return th.mean((output - target) ** 2)\n",
    "\n",
    "\n",
    "del mseloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f607f8271d895518",
   "metadata": {},
   "source": [
    "In our case, we will use the `CrossEntropyLoss`, as we are dealing with a classification task.\n",
    "\n",
    "\n",
    "You can find the specifics of this *loss* in PyTorch [here](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), but what is really worth pointing out is that it is assumed that the input(s) are *'raw, unnormalized scores for each class'*. This means that we shouldn't include any softmax in the network architecture, since it is already included by this implementation of the CE loss!\n",
    "\n",
    "Or we could include it, but then we should use the [`NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html) (Negative Log-Likelihood Loss) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209b750eb1c222",
   "metadata": {},
   "source": [
    "### The optimization process\n",
    "\n",
    "With the `autodiff` engine allowing us to compute gradients of (almost) any function - specifically, we will be interested the loss function of our model -, it is time to figure out what to do with these gradients!\n",
    "\n",
    "In PyTorch, it is straightforward to apply most first-order optimization techniques - *e.g.* Gradient Descent and its variations, such as SGD, Adam, RMSProp *etc...* - to the parameters of an `nn.Model`.\n",
    "\n",
    "The `torch.optim` module provides a set of classes implementing some of these algorithms, which can be found [here](https://pytorch.org/docs/stable/optim.html#algorithms).\n",
    "\n",
    "However, before building and applying such an optimizer to our model, we need to instantiate the actual model and move it to the device we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f471998ac2916a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.572847Z",
     "start_time": "2024-04-08T12:44:01.241501Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.602737Z",
     "iopub.status.busy": "2024-04-08T12:56:57.602500Z",
     "iopub.status.idle": "2024-04-08T12:56:57.819989Z",
     "shell.execute_reply": "2024-04-08T12:56:57.818894Z"
    }
   },
   "outputs": [],
   "source": [
    "# In our case...\n",
    "model: th.nn.Module = define_myseqmlp(28 * 28, 128, 10).to(\n",
    "    device\n",
    ")  # Remember to move the model to the appropriate device!\n",
    "# By default, it is on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5438e497f36a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.577802Z",
     "start_time": "2024-04-08T12:44:01.574379Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.822893Z",
     "iopub.status.busy": "2024-04-08T12:56:57.822646Z",
     "iopub.status.idle": "2024-04-08T12:56:57.826777Z",
     "shell.execute_reply": "2024-04-08T12:56:57.825641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's define the optimizer\n",
    "optimizer: th.optim.Optimizer = th.optim.Adam(\n",
    "    params=model.parameters(), lr=LR, weight_decay=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0cc81271c9899",
   "metadata": {},
   "source": [
    "Using an optimizer is generally very simple. There are three main steps involved:\n",
    "\n",
    "- zeroing any current gradient information left attached to the parameters: `optimizer.zero_grad()`,\n",
    "- computing the derivatives of the loss *w.r.t.* the parameters and storing such gradient information: `loss.backward()`,\n",
    "- performing a parameter update step in the loss-minimizing direction: `optimizer.step()`.\n",
    "\n",
    "Note that the first step should always be performed unless we do want PyTorch to accumulate gradients!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e3f974b34c7d6",
   "metadata": {},
   "source": [
    "#### Learning rate scheduling\n",
    "\n",
    "In practice, it is often useful to vary the learning rate during training. For example you may want to use a large learning rate in the initial phase of training to quickly descend the loss and then you may want to decrease it to be more precise around a minimum.\n",
    "\n",
    "This can be done in many ways, but the most common is to use a *learning rate scheduler*. In PyTorch, a learning rate scheduler is an object that takes an optimizer and updates the learning rate according to some rule. You can find the list of available schedulers in the [official documentation](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate).\n",
    "\n",
    "The simplest LR scheduler is `torch.optim.lr_scheduler.ExponentialLR`, which takes an existing optimizer (with learning rate $\\lambda$) and a parameter $\\gamma$. It multiplies the learning rate by $\\gamma$ every given time `scheduler.step()` is called (*e.g.* at every batch, or at every epoch). *I.e.:*\n",
    "\n",
    "$$\n",
    "\\lambda_{\\text{i+1}} \\leftarrow \\gamma\\lambda_{\\text{i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ae35af76879ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:44:01.582380Z",
     "start_time": "2024-04-08T12:44:01.578939Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.828747Z",
     "iopub.status.busy": "2024-04-08T12:56:57.828443Z",
     "iopub.status.idle": "2024-04-08T12:56:57.832749Z",
     "shell.execute_reply": "2024-04-08T12:56:57.831320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's define the scheduler\n",
    "scheduler: th.optim.lr_scheduler.LRScheduler = th.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer, gamma=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264ef84daafa789",
   "metadata": {},
   "source": [
    "### The (actual) training loop\n",
    "```\n",
    "Loop over epochs:\n",
    "    Loop over data:\n",
    "        Perform a forward pass\n",
    "        Compute the loss\n",
    "        Zero-out past gradients\n",
    "        Perform a backward pass\n",
    "        Update model parameters\n",
    "       (Update the learning rate)\n",
    "   (Compute validation metric)\n",
    "```\n",
    "\n",
    "Gradient-based training is an iterative process, that we repeat for a (usually) fixed number of epochs. At each epoch, we traverse the whole dataset by randomly drawn mini-batches of a fixed number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3043f7b9ba6bb0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:46:25.563497Z",
     "start_time": "2024-04-08T12:44:01.583771Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:56:57.835923Z",
     "iopub.status.busy": "2024-04-08T12:56:57.835455Z",
     "iopub.status.idle": "2024-04-08T12:59:44.253738Z",
     "shell.execute_reply": "2024-04-08T12:59:44.253235Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_losses: List[float] = []\n",
    "eval_acc: List[float] = []\n",
    "test_acc: List[float] = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in trange(EPOCHS, desc=\"Training epoch\"):\n",
    "\n",
    "    model.train()  # Remember to set the model in training mode before actual training\n",
    "\n",
    "    # Loop over data\n",
    "    for batch_idx, batched_datapoint in enumerate(train_loader):\n",
    "\n",
    "        x, y = batched_datapoint\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass + loss computation\n",
    "        loss = CRITERION(model(x), y)\n",
    "\n",
    "        # Zero-out past gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Log the loss and accuracy on the training set...\n",
    "    num_elem: int = 0\n",
    "    trackingmetric: float = 0\n",
    "    trackingcorrect: int = 0\n",
    "\n",
    "    model.eval()  # Remember to set the model in evaluation mode before evaluating it\n",
    "\n",
    "    # Since we are just evaluating the model, we don't need to compute gradients\n",
    "    with th.no_grad():\n",
    "        # ... by looping over training data again\n",
    "        for _, batched_datapoint_e in enumerate(train_loader):\n",
    "            x_e, y_e = batched_datapoint_e\n",
    "            x_e, y_e = x_e.to(device), y_e.to(device)\n",
    "            modeltarget_e = model(x_e)\n",
    "            ypred_e = th.argmax(modeltarget_e, dim=1, keepdim=True)\n",
    "            trackingmetric += CRITERION(modeltarget_e, y_e).item()\n",
    "            trackingcorrect += ypred_e.eq(y_e.view_as(ypred_e)).sum().item()\n",
    "            num_elem += x_e.shape[0]\n",
    "        eval_losses.append(trackingmetric / num_elem)\n",
    "        eval_acc.append(trackingcorrect / num_elem)\n",
    "\n",
    "    # Let's ignore for now what the next line does... üôà\n",
    "    test_acc.append(\n",
    "        eval_model_on_test(\n",
    "            model, True, test_loader, device, th.nn.CrossEntropyLoss(), False\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2f5b35d98e167",
   "metadata": {},
   "source": [
    "Notice the `model.train()` and `model.eval()` calls, and the `torch.no_grad()` context manager.\n",
    "\n",
    "The former two inform the model (and its submodules) that we are either training or evaluating it. This is important because some modules are developed to behave differently during training and evaluation (*e.g.* dropout, batch normalization, etc...).\n",
    "\n",
    "The latter switches off gradient-tracking operations: this allows to make computations lighter and to avoid performing gradient descent steps by mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5d2918a51aa20",
   "metadata": {},
   "source": [
    "### Final evaluation\n",
    "\n",
    "Let's see how the loss and accuracy of the model - evaluated on the **training set** - evolved during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082a563e8c13fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:53:03.057016Z",
     "start_time": "2024-04-08T12:53:02.657196Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:59:44.256240Z",
     "iopub.status.busy": "2024-04-08T12:59:44.256092Z",
     "iopub.status.idle": "2024-04-08T12:59:44.394400Z",
     "shell.execute_reply": "2024-04-08T12:59:44.393756Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_color = \"tab:red\"\n",
    "acc_color = \"tab:blue\"\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\", color=loss_color)\n",
    "ax1.plot(eval_losses, color=loss_color)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=loss_color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Accuracy\", color=acc_color)\n",
    "ax2.plot(eval_acc, color=acc_color)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=acc_color)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.title(\"Training loss and accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463ee2a6e537246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:46:25.703747Z",
     "start_time": "2024-04-08T12:46:25.700701Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:59:44.396686Z",
     "iopub.status.busy": "2024-04-08T12:59:44.396504Z",
     "iopub.status.idle": "2024-04-08T12:59:44.399707Z",
     "shell.execute_reply": "2024-04-08T12:59:44.399158Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Final training loss: {eval_losses[-1]}\")\n",
    "print(f\"Final training accuracy: {eval_acc[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447170171ee78be9",
   "metadata": {},
   "source": [
    "Accuracy on the training set is not a good indicator of the model's performance. We should evaluate it on the **test set** to have a more reliable estimate of the model's generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc867653fa0cd8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:46:26.660003Z",
     "start_time": "2024-04-08T12:46:25.704765Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:59:44.401676Z",
     "iopub.status.busy": "2024-04-08T12:59:44.401535Z",
     "iopub.status.idle": "2024-04-08T12:59:45.307954Z",
     "shell.execute_reply": "2024-04-08T12:59:45.307245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's evaluate the model on the test set\n",
    "model.eval()\n",
    "num_elem: int = 0\n",
    "trackingcorrect: int = 0\n",
    "\n",
    "with th.no_grad():\n",
    "    for _, batched_datapoint_e in enumerate(test_loader):\n",
    "        x_e, y_e = batched_datapoint_e\n",
    "        x_e, y_e = x_e.to(device), y_e.to(device)\n",
    "        modeltarget_e = model(x_e)\n",
    "        ypred_e = th.argmax(modeltarget_e, dim=1, keepdim=True)\n",
    "        trackingcorrect += ypred_e.eq(y_e.view_as(ypred_e)).sum().item()\n",
    "        num_elem += x_e.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cbd739293e70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:46:26.665800Z",
     "start_time": "2024-04-08T12:46:26.661308Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:59:45.310699Z",
     "iopub.status.busy": "2024-04-08T12:59:45.310131Z",
     "iopub.status.idle": "2024-04-08T12:59:45.313298Z",
     "shell.execute_reply": "2024-04-08T12:59:45.312841Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Final test accuracy: {trackingcorrect / num_elem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a72e9bfd854445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:53:17.805277Z",
     "start_time": "2024-04-08T12:53:17.704343Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-08T12:59:45.315308Z",
     "iopub.status.busy": "2024-04-08T12:59:45.314787Z",
     "iopub.status.idle": "2024-04-08T12:59:45.405912Z",
     "shell.execute_reply": "2024-04-08T12:59:45.404996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's plot the accuracy on the train vs test set\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.plot(eval_acc, label=\"Train\", color=\"tab:blue\")\n",
    "ax.plot(test_acc, label=\"Test\", color=\"tab:orange\")\n",
    "ax.legend()\n",
    "\n",
    "plt.title(\"Training vs. Test accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "11389ffee21743e49686b737c1619eaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52e747deb71f4a358e9343db7e5dd355": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59774396ce4b42b8992cbab332836cf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e355226f6dca42ec8cebfb7832214573",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6d022da7073a4dc59800542fd506ce7b",
       "tabbable": null,
       "tooltip": null,
       "value": 10
      }
     },
     "5f31e9c86c2848f4b92ab98ac8da4090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f7776336906f4ea4b1315d325d89c676",
        "IPY_MODEL_59774396ce4b42b8992cbab332836cf3",
        "IPY_MODEL_ab6c283daf4a43cc971435aa4fc10381"
       ],
       "layout": "IPY_MODEL_11389ffee21743e49686b737c1619eaf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6d022da7073a4dc59800542fd506ce7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "88be0ed90b2e418eb834d08f8b564aee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9cee15fb886f4861bc74238bcbdccafb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab6c283daf4a43cc971435aa4fc10381": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_52e747deb71f4a358e9343db7e5dd355",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_88be0ed90b2e418eb834d08f8b564aee",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá10/10‚Äá[02:46&lt;00:00,‚Äá15.42s/it]"
      }
     },
     "b95377a0cd4a479aac7acdf048b89088": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e355226f6dca42ec8cebfb7832214573": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7776336906f4ea4b1315d325d89c676": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9cee15fb886f4861bc74238bcbdccafb",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_b95377a0cd4a479aac7acdf048b89088",
       "tabbable": null,
       "tooltip": null,
       "value": "Training‚Äáepoch:‚Äá100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
